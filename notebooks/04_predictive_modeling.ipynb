{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictive Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 58,502 records\n",
            "Shape: (58502, 23)\n",
            "\n",
            "Columns: ['tourney_id', 'tourney_name', 'tourney_date', 'surface', 'round', 'draw_size', 'player_A_id', 'player_A_name', 'player_A_rank', 'player_A_rank_points', 'player_A_age', 'player_A_ht', 'player_B_id', 'player_B_name', 'player_B_rank', 'player_B_rank_points', 'player_B_age', 'player_B_ht', 'delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points', 'target']\n",
            "Created delta_rank_missing: 1,222 missing values (2.09%)\n",
            "Created delta_age_missing: 6 missing values (0.01%)\n",
            "Created delta_ht_missing: 2,271 missing values (3.88%)\n",
            "Created delta_rank_points_missing: 1,222 missing values (2.09%)\n",
            "\n",
            "Imputing missing values with 0:\n",
            "  delta_rank: imputed 1,222 missing values\n",
            "  delta_age: imputed 6 missing values\n",
            "  delta_ht: imputed 2,271 missing values\n",
            "  delta_rank_points: imputed 1,222 missing values\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tourney_id</th>\n",
              "      <th>tourney_name</th>\n",
              "      <th>tourney_date</th>\n",
              "      <th>surface</th>\n",
              "      <th>round</th>\n",
              "      <th>draw_size</th>\n",
              "      <th>player_A_id</th>\n",
              "      <th>player_A_name</th>\n",
              "      <th>player_A_rank</th>\n",
              "      <th>player_A_rank_points</th>\n",
              "      <th>...</th>\n",
              "      <th>player_B_ht</th>\n",
              "      <th>delta_rank</th>\n",
              "      <th>delta_age</th>\n",
              "      <th>delta_ht</th>\n",
              "      <th>delta_rank_points</th>\n",
              "      <th>target</th>\n",
              "      <th>delta_rank_missing</th>\n",
              "      <th>delta_age_missing</th>\n",
              "      <th>delta_ht_missing</th>\n",
              "      <th>delta_rank_points_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-1536</td>\n",
              "      <td>Madrid Masters</td>\n",
              "      <td>20051017</td>\n",
              "      <td>Hard</td>\n",
              "      <td>R64</td>\n",
              "      <td>48</td>\n",
              "      <td>102720</td>\n",
              "      <td>Tomas Zib</td>\n",
              "      <td>63.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>...</td>\n",
              "      <td>198.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-206.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-1536</td>\n",
              "      <td>Madrid Masters</td>\n",
              "      <td>20051017</td>\n",
              "      <td>Hard</td>\n",
              "      <td>R64</td>\n",
              "      <td>48</td>\n",
              "      <td>102845</td>\n",
              "      <td>Carlos Moya</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>...</td>\n",
              "      <td>183.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-1536</td>\n",
              "      <td>Madrid Masters</td>\n",
              "      <td>20051017</td>\n",
              "      <td>Hard</td>\n",
              "      <td>R64</td>\n",
              "      <td>48</td>\n",
              "      <td>102450</td>\n",
              "      <td>Tim Henman</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>188.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-1536</td>\n",
              "      <td>Madrid Masters</td>\n",
              "      <td>20051017</td>\n",
              "      <td>Hard</td>\n",
              "      <td>R64</td>\n",
              "      <td>48</td>\n",
              "      <td>104022</td>\n",
              "      <td>Mikhail Youzhny</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1090.0</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>412.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-1536</td>\n",
              "      <td>Madrid Masters</td>\n",
              "      <td>20051017</td>\n",
              "      <td>Hard</td>\n",
              "      <td>R64</td>\n",
              "      <td>48</td>\n",
              "      <td>103017</td>\n",
              "      <td>Nicolas Kiefer</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>...</td>\n",
              "      <td>180.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  tourney_id    tourney_name  tourney_date surface round  draw_size  \\\n",
              "0  2005-1536  Madrid Masters      20051017    Hard   R64         48   \n",
              "1  2005-1536  Madrid Masters      20051017    Hard   R64         48   \n",
              "2  2005-1536  Madrid Masters      20051017    Hard   R64         48   \n",
              "3  2005-1536  Madrid Masters      20051017    Hard   R64         48   \n",
              "4  2005-1536  Madrid Masters      20051017    Hard   R64         48   \n",
              "\n",
              "   player_A_id    player_A_name  player_A_rank  player_A_rank_points  ...  \\\n",
              "0       102720        Tomas Zib           63.0                 621.0  ...   \n",
              "1       102845      Carlos Moya           33.0                1005.0  ...   \n",
              "2       102450       Tim Henman           26.0                1120.0  ...   \n",
              "3       104022  Mikhail Youzhny           29.0                1090.0  ...   \n",
              "4       103017   Nicolas Kiefer           30.0                1070.0  ...   \n",
              "\n",
              "   player_B_ht  delta_rank  delta_age delta_ht  delta_rank_points  target  \\\n",
              "0        198.0        21.0        5.5    -20.0             -206.0       0   \n",
              "1        183.0        -8.0        5.0      7.0              169.0       1   \n",
              "2        188.0        -2.0        6.7     -3.0                5.0       1   \n",
              "3        190.0       -26.0        0.4     -7.0              412.0       0   \n",
              "4        180.0       -15.0        4.7      3.0              299.0       0   \n",
              "\n",
              "   delta_rank_missing  delta_age_missing  delta_ht_missing  \\\n",
              "0                   0                  0                 0   \n",
              "1                   0                  0                 0   \n",
              "2                   0                  0                 0   \n",
              "3                   0                  0                 0   \n",
              "4                   0                  0                 0   \n",
              "\n",
              "   delta_rank_points_missing  \n",
              "0                          0  \n",
              "1                          0  \n",
              "2                          0  \n",
              "3                          0  \n",
              "4                          0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the match-level dataset\n",
        "data_path = Path(\"../data/clean-match/atp_matches_match_level_1.csv\")\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Loaded {len(df):,} records\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "# Create binary missing value indicators for baseline features\n",
        "baseline_features = ['delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points']\n",
        "for feature in baseline_features:\n",
        "    if feature in df.columns:\n",
        "        missing_col = f'{feature}_missing'\n",
        "        df[missing_col] = df[feature].isna().astype(int)\n",
        "        print(f\"Created {missing_col}: {df[missing_col].sum():,} missing values ({df[missing_col].mean():.2%})\")\n",
        "\n",
        "# Impute missing values with 0 (before standardization)\n",
        "print(\"\\nImputing missing values with 0:\")\n",
        "for feature in baseline_features:\n",
        "    if feature in df.columns:\n",
        "        missing_count = df[feature].isna().sum()\n",
        "        df[feature] = df[feature].fillna(0)\n",
        "        print(f\"  {feature}: imputed {missing_count:,} missing values\")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 46,259 rows (2006-2021)\n",
            "Test set:      8,979 rows (2022-2024)\n",
            "\n",
            "Training set year range: 2006 - 2021\n",
            "Test set year range:      2022 - 2024\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into training (2006-2021) and test (2022-2024) based on match date\n",
        "# Extract year from tourney_date (format: YYYYMMDD)\n",
        "df['year'] = pd.to_numeric(\n",
        "    df['tourney_date'].astype(str).str[:4], \n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Create train/test masks\n",
        "train_mask = (df['year'] >= 2006) & (df['year'] <= 2021)\n",
        "test_mask = (df['year'] >= 2022) & (df['year'] <= 2024)\n",
        "\n",
        "# Split the data\n",
        "df_train = df[train_mask].copy()\n",
        "df_test = df[test_mask].copy()\n",
        "\n",
        "print(f\"Training set: {len(df_train):,} rows (2006-2021)\")\n",
        "print(f\"Test set:      {len(df_test):,} rows (2022-2024)\")\n",
        "print(f\"\\nTraining set year range: {df_train['year'].min():.0f} - {df_train['year'].max():.0f}\")\n",
        "print(f\"Test set year range:      {df_test['year'].min():.0f} - {df_test['year'].max():.0f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "  Features shape: (46259, 8)\n",
            "  Target shape: (46259,)\n",
            "\n",
            "Test set:\n",
            "  Features shape: (8979, 8)\n",
            "  Target shape: (8979,)\n",
            "\n",
            "Features (8): ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points_missing', 'delta_rank_missing', 'delta_age_missing', 'delta_ht_missing']\n",
            "\n",
            "Target distribution (train):\n",
            "target\n",
            "0    23050\n",
            "1    23209\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target distribution (test):\n",
            "target\n",
            "0    4528\n",
            "1    4451\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Select features and target\n",
        "# Include both imputed delta features and their missingness indicators\n",
        "delta_features = ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht']\n",
        "missing_indicators = [f'{feat}_missing' for feat in delta_features]\n",
        "feature_cols = delta_features + missing_indicators\n",
        "target_col = 'target'\n",
        "\n",
        "# Create feature matrices and target vectors\n",
        "X_train = df_train[feature_cols]\n",
        "X_test = df_test[feature_cols]\n",
        "y_train = df_train[target_col]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "print(f\"Training set:\")\n",
        "print(f\"  Features shape: {X_train.shape}\")\n",
        "print(f\"  Target shape: {y_train.shape}\")\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Features shape: {X_test.shape}\")\n",
        "print(f\"  Target shape: {y_test.shape}\")\n",
        "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
        "print(f\"\\nTarget distribution (train):\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(f\"\\nTarget distribution (test):\")\n",
        "print(y_test.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized training features - mean values (should be near zero):\n",
            "delta_rank_points           -0.0\n",
            "delta_rank                   0.0\n",
            "delta_age                   -0.0\n",
            "delta_ht                     0.0\n",
            "delta_rank_points_missing   -0.0\n",
            "delta_rank_missing          -0.0\n",
            "delta_age_missing            0.0\n",
            "delta_ht_missing             0.0\n",
            "dtype: float64\n",
            "\n",
            "Standardized training features - std values (should be ~1.0):\n",
            "delta_rank_points            1.000011\n",
            "delta_rank                   1.000011\n",
            "delta_age                    1.000011\n",
            "delta_ht                     1.000011\n",
            "delta_rank_points_missing    1.000011\n",
            "delta_rank_missing           1.000011\n",
            "delta_age_missing            1.000011\n",
            "delta_ht_missing             1.000011\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Standardize features using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit scaler on training data only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrames to preserve column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Standardized training features - mean values (should be near zero):\")\n",
        "print(X_train_scaled.mean().round(6))\n",
        "print(f\"\\nStandardized training features - std values (should be ~1.0):\")\n",
        "print(X_train_scaled.std().round(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model Trained\n",
            "Number of iterations: 9\n",
            "Regularization strength (C): 1.0\n",
            "\n",
            "Model Coefficients (sorted by absolute value):\n",
            "============================================================\n",
            "                  feature  coefficient\n",
            "        delta_rank_points     0.801364\n",
            "               delta_rank    -0.506150\n",
            "                 delta_ht     0.107098\n",
            "                delta_age    -0.060202\n",
            "delta_rank_points_missing     0.048178\n",
            "       delta_rank_missing     0.048178\n",
            "         delta_ht_missing     0.044656\n",
            "        delta_age_missing    -0.024570\n"
          ]
        }
      ],
      "source": [
        "# Train logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Use default regularization (C=1.0)\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Logistic Regression Model Trained\")\n",
        "print(f\"Number of iterations: {lr_model.n_iter_[0]}\")\n",
        "print(f\"Regularization strength (C): {lr_model.C}\")\n",
        "\n",
        "# Get coefficients with feature names\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'coefficient': lr_model.coef_[0]\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coefficients['abs_coefficient'] = coefficients['coefficient'].abs()\n",
        "coefficients = coefficients.sort_values('abs_coefficient', ascending=False).drop(columns='abs_coefficient')\n",
        "\n",
        "print(\"\\nModel Coefficients (sorted by absolute value):\")\n",
        "print(\"=\" * 60)\n",
        "print(coefficients.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance on Test Set:\n",
            "==================================================\n",
            "ROC AUC:  0.7008\n",
            "Log Loss: 0.6317\n",
            "\n",
            "==================================================\n",
            "Model Coefficients (including missingness indicators):\n",
            "==================================================\n",
            "                  feature  coefficient\n",
            "        delta_rank_points     0.801364\n",
            "               delta_rank    -0.506150\n",
            "                 delta_ht     0.107098\n",
            "                delta_age    -0.060202\n",
            "delta_rank_points_missing     0.048178\n",
            "       delta_rank_missing     0.048178\n",
            "         delta_ht_missing     0.044656\n",
            "        delta_age_missing    -0.024570\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "log_loss_score = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Model Performance on Test Set:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ROC AUC:  {roc_auc:.4f}\")\n",
        "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
        "\n",
        "# Display updated coefficients including missingness indicators\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Model Coefficients (including missingness indicators):\")\n",
        "print(\"=\" * 50)\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'coefficient': lr_model.coef_[0]\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coefficients['abs_coefficient'] = coefficients['coefficient'].abs()\n",
        "coefficients = coefficients.sort_values('abs_coefficient', ascending=False).drop(columns='abs_coefficient')\n",
        "\n",
        "print(coefficients.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating rolling 52-week win percentages...\n",
            "Total matches: 58,502\n"
          ]
        }
      ],
      "source": [
        "# Calculate rolling 52-week win percentage for each player\n",
        "# Convert tourney_date to datetime for date calculations\n",
        "df['match_date'] = pd.to_datetime(df['tourney_date'].astype(str), format='%Y%m%d', errors='coerce')\n",
        "\n",
        "# Sort by player and date for efficient calculation\n",
        "df_sorted = df.sort_values(['player_A_id', 'match_date']).copy()\n",
        "\n",
        "print(\"Calculating rolling 52-week win percentages...\")\n",
        "print(f\"Total matches: {len(df_sorted):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating win percentages for player A...\n",
            "Calculating win percentages for player B...\n",
            "\n",
            "Win percentage statistics:\n",
            "Player A win pct - mean: 0.503, missing: 1,794\n",
            "Player B win pct - mean: 0.502, missing: 2,914\n",
            "Delta win pct - mean: 0.002, missing: 4,144\n",
            "Player A no history: 1,794 (3.07%)\n",
            "Player B no history: 2,914 (4.98%)\n"
          ]
        }
      ],
      "source": [
        "# Calculate win percentage for each player over rolling 52-week window\n",
        "# Exclude the current match from calculations\n",
        "# A player can appear as either player A or player B in different matches\n",
        "\n",
        "def calculate_win_pct(row, df_all, player_id, date_col):\n",
        "    \"\"\"Calculate 52-week rolling win percentage for a player, excluding current match\"\"\"\n",
        "    match_date = row[date_col]\n",
        "    \n",
        "    if pd.isna(match_date) or pd.isna(player_id):\n",
        "        return np.nan, False  # (win_pct, has_history)\n",
        "    \n",
        "    # Define 52-week window (365 days before current match)\n",
        "    window_start = match_date - pd.Timedelta(days=365)\n",
        "    \n",
        "    # Get all matches for this player in the 52-week window, excluding current match\n",
        "    # Player can be either player A or player B\n",
        "    player_matches = df_all[\n",
        "        ((df_all['player_A_id'] == player_id) | (df_all['player_B_id'] == player_id)) &\n",
        "        (df_all[date_col] >= window_start) &\n",
        "        (df_all[date_col] < match_date)  # Exclude current match\n",
        "    ].copy()\n",
        "    \n",
        "    if len(player_matches) == 0:\n",
        "        return np.nan, False  # No history\n",
        "    \n",
        "    # Calculate wins: player wins if they are player A and target=1, or player B and target=0\n",
        "    wins = (\n",
        "        ((player_matches['player_A_id'] == player_id) & (player_matches['target'] == 1)) |\n",
        "        ((player_matches['player_B_id'] == player_id) & (player_matches['target'] == 0))\n",
        "    ).sum()\n",
        "    \n",
        "    total_matches = len(player_matches)\n",
        "    win_pct = wins / total_matches if total_matches > 0 else np.nan\n",
        "    \n",
        "    return win_pct, True\n",
        "\n",
        "# Calculate win percentages for player A and player B\n",
        "print(\"Calculating win percentages for player A...\")\n",
        "df_sorted['player_A_win_pct_52w'] = df_sorted.apply(\n",
        "    lambda row: calculate_win_pct(row, df_sorted, row['player_A_id'], 'match_date')[0],\n",
        "    axis=1\n",
        ")\n",
        "df_sorted['player_A_has_history'] = df_sorted.apply(\n",
        "    lambda row: calculate_win_pct(row, df_sorted, row['player_A_id'], 'match_date')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"Calculating win percentages for player B...\")\n",
        "df_sorted['player_B_win_pct_52w'] = df_sorted.apply(\n",
        "    lambda row: calculate_win_pct(row, df_sorted, row['player_B_id'], 'match_date')[0],\n",
        "    axis=1\n",
        ")\n",
        "df_sorted['player_B_has_history'] = df_sorted.apply(\n",
        "    lambda row: calculate_win_pct(row, df_sorted, row['player_B_id'], 'match_date')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Calculate delta win percentage\n",
        "df_sorted['delta_win_pct_52w'] = df_sorted['player_A_win_pct_52w'] - df_sorted['player_B_win_pct_52w']\n",
        "\n",
        "# Create missing-history indicators\n",
        "df_sorted['player_A_no_history'] = (~df_sorted['player_A_has_history']).astype(int)\n",
        "df_sorted['player_B_no_history'] = (~df_sorted['player_B_has_history']).astype(int)\n",
        "\n",
        "print(f\"\\nWin percentage statistics:\")\n",
        "print(f\"Player A win pct - mean: {df_sorted['player_A_win_pct_52w'].mean():.3f}, missing: {df_sorted['player_A_win_pct_52w'].isna().sum():,}\")\n",
        "print(f\"Player B win pct - mean: {df_sorted['player_B_win_pct_52w'].mean():.3f}, missing: {df_sorted['player_B_win_pct_52w'].isna().sum():,}\")\n",
        "print(f\"Delta win pct - mean: {df_sorted['delta_win_pct_52w'].mean():.3f}, missing: {df_sorted['delta_win_pct_52w'].isna().sum():,}\")\n",
        "print(f\"Player A no history: {df_sorted['player_A_no_history'].sum():,} ({df_sorted['player_A_no_history'].mean():.2%})\")\n",
        "print(f\"Player B no history: {df_sorted['player_B_no_history'].sum():,} ({df_sorted['player_B_no_history'].mean():.2%})\")\n",
        "\n",
        "# Update df with the new features\n",
        "df = df_sorted.sort_index().copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 46,259 rows (2006-2021)\n",
            "Test set:      8,979 rows (2022-2024)\n"
          ]
        }
      ],
      "source": [
        "# Re-split dataset with new features (same temporal split)\n",
        "df['year'] = pd.to_numeric(\n",
        "    df['tourney_date'].astype(str).str[:4], \n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "train_mask = (df['year'] >= 2006) & (df['year'] <= 2021)\n",
        "test_mask = (df['year'] >= 2022) & (df['year'] <= 2024)\n",
        "\n",
        "df_train = df[train_mask].copy()\n",
        "df_test = df[test_mask].copy()\n",
        "\n",
        "print(f\"Training set: {len(df_train):,} rows (2006-2021)\")\n",
        "print(f\"Test set:      {len(df_test):,} rows (2022-2024)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "  Features shape: (46259, 11)\n",
            "  Target shape: (46259,)\n",
            "\n",
            "Test set:\n",
            "  Features shape: (8979, 11)\n",
            "  Target shape: (8979,)\n",
            "\n",
            "Features (11): ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points_missing', 'delta_rank_missing', 'delta_age_missing', 'delta_ht_missing', 'delta_win_pct_52w', 'player_A_no_history', 'player_B_no_history']\n",
            "\n",
            "Missing values in training set:\n",
            "delta_rank_points            0\n",
            "delta_rank                   0\n",
            "delta_age                    0\n",
            "delta_ht                     0\n",
            "delta_rank_points_missing    0\n",
            "delta_rank_missing           0\n",
            "delta_age_missing            0\n",
            "delta_ht_missing             0\n",
            "delta_win_pct_52w            0\n",
            "player_A_no_history          0\n",
            "player_B_no_history          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Select features including win percentage features\n",
        "delta_features = ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht']\n",
        "missing_indicators = [f'{feat}_missing' for feat in delta_features]\n",
        "win_pct_features = ['delta_win_pct_52w']\n",
        "history_indicators = ['player_A_no_history', 'player_B_no_history']\n",
        "\n",
        "feature_cols = delta_features + missing_indicators + win_pct_features + history_indicators\n",
        "target_col = 'target'\n",
        "\n",
        "# Create feature matrices and target vectors\n",
        "X_train = df_train[feature_cols].copy()\n",
        "X_test = df_test[feature_cols].copy()\n",
        "y_train = df_train[target_col]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "# Impute missing values in win percentage with 0 (for players with no history)\n",
        "X_train['delta_win_pct_52w'] = X_train['delta_win_pct_52w'].fillna(0)\n",
        "X_test['delta_win_pct_52w'] = X_test['delta_win_pct_52w'].fillna(0)\n",
        "\n",
        "print(f\"Training set:\")\n",
        "print(f\"  Features shape: {X_train.shape}\")\n",
        "print(f\"  Target shape: {y_train.shape}\")\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Features shape: {X_test.shape}\")\n",
        "print(f\"  Target shape: {y_test.shape}\")\n",
        "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
        "print(f\"\\nMissing values in training set:\")\n",
        "print(X_train.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized training features - mean values (should be near zero):\n",
            "delta_rank_points           -0.0\n",
            "delta_rank                   0.0\n",
            "delta_age                   -0.0\n",
            "delta_ht                     0.0\n",
            "delta_rank_points_missing   -0.0\n",
            "delta_rank_missing          -0.0\n",
            "delta_age_missing            0.0\n",
            "delta_ht_missing             0.0\n",
            "delta_win_pct_52w           -0.0\n",
            "player_A_no_history          0.0\n",
            "player_B_no_history          0.0\n",
            "dtype: float64\n",
            "\n",
            "Standardized training features - std values (should be ~1.0):\n",
            "delta_rank_points            1.000011\n",
            "delta_rank                   1.000011\n",
            "delta_age                    1.000011\n",
            "delta_ht                     1.000011\n",
            "delta_rank_points_missing    1.000011\n",
            "delta_rank_missing           1.000011\n",
            "delta_age_missing            1.000011\n",
            "delta_ht_missing             1.000011\n",
            "delta_win_pct_52w            1.000011\n",
            "player_A_no_history          1.000011\n",
            "player_B_no_history          1.000011\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Standardize features using StandardScaler (with win percentage features)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit scaler on training data only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrames to preserve column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Standardized training features - mean values (should be near zero):\")\n",
        "print(X_train_scaled.mean().round(6))\n",
        "print(f\"\\nStandardized training features - std values (should be ~1.0):\")\n",
        "print(X_train_scaled.std().round(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model Trained (with win percentage features)\n",
            "Number of iterations: 8\n",
            "Regularization strength (C): 1.0\n"
          ]
        }
      ],
      "source": [
        "# Retrain logistic regression model with win percentage features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Use default regularization (C=1.0)\n",
        "lr_model_winpct = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model_winpct.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Logistic Regression Model Trained (with win percentage features)\")\n",
        "print(f\"Number of iterations: {lr_model_winpct.n_iter_[0]}\")\n",
        "print(f\"Regularization strength (C): {lr_model_winpct.C}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance on Test Set (with win percentage features):\n",
            "============================================================\n",
            "ROC AUC:  0.7011\n",
            "Log Loss: 0.6304\n",
            "\n",
            "============================================================\n",
            "Model Coefficients (including win percentage and history indicators):\n",
            "============================================================\n",
            "                  feature  coefficient\n",
            "        delta_rank_points     0.619405\n",
            "               delta_rank    -0.376798\n",
            "        delta_win_pct_52w     0.291340\n",
            "      player_B_no_history     0.125546\n",
            "                 delta_ht     0.091360\n",
            "      player_A_no_history    -0.086261\n",
            "                delta_age    -0.060970\n",
            "delta_rank_points_missing     0.041618\n",
            "       delta_rank_missing     0.041618\n",
            "         delta_ht_missing     0.038814\n",
            "        delta_age_missing    -0.024139\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_pred_proba = lr_model_winpct.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "log_loss_score = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Model Performance on Test Set (with win percentage features):\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ROC AUC:  {roc_auc:.4f}\")\n",
        "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
        "\n",
        "# Display updated coefficients including all features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Model Coefficients (including win percentage and history indicators):\")\n",
        "print(\"=\" * 60)\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'coefficient': lr_model_winpct.coef_[0]\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coefficients['abs_coefficient'] = coefficients['coefficient'].abs()\n",
        "coefficients = coefficients.sort_values('abs_coefficient', ascending=False).drop(columns='abs_coefficient')\n",
        "\n",
        "print(coefficients.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating surface-specific win percentages...\n"
          ]
        }
      ],
      "source": [
        "# Calculate surface-specific rolling 52-week win percentage for each player\n",
        "# Only use matches on the same surface as the current match\n",
        "\n",
        "def calculate_surface_win_pct(row, df_all, player_id, date_col, surface_col):\n",
        "    \"\"\"Calculate 52-week rolling win percentage for a player on a specific surface, excluding current match\"\"\"\n",
        "    match_date = row[date_col]\n",
        "    surface = row[surface_col]\n",
        "    \n",
        "    if pd.isna(match_date) or pd.isna(player_id) or pd.isna(surface):\n",
        "        return np.nan, False  # (win_pct, has_history)\n",
        "    \n",
        "    # Define 52-week window (365 days before current match)\n",
        "    window_start = match_date - pd.Timedelta(days=365)\n",
        "    \n",
        "    # Get all matches for this player on the same surface in the 52-week window, excluding current match\n",
        "    player_matches = df_all[\n",
        "        ((df_all['player_A_id'] == player_id) | (df_all['player_B_id'] == player_id)) &\n",
        "        (df_all[surface_col] == surface) &\n",
        "        (df_all[date_col] >= window_start) &\n",
        "        (df_all[date_col] < match_date)  # Exclude current match\n",
        "    ].copy()\n",
        "    \n",
        "    if len(player_matches) == 0:\n",
        "        return np.nan, False  # No history on this surface\n",
        "    \n",
        "    # Calculate wins: player wins if they are player A and target=1, or player B and target=0\n",
        "    wins = (\n",
        "        ((player_matches['player_A_id'] == player_id) & (player_matches['target'] == 1)) |\n",
        "        ((player_matches['player_B_id'] == player_id) & (player_matches['target'] == 0))\n",
        "    ).sum()\n",
        "    \n",
        "    total_matches = len(player_matches)\n",
        "    win_pct = wins / total_matches if total_matches > 0 else np.nan\n",
        "    \n",
        "    return win_pct, True\n",
        "\n",
        "print(\"Calculating surface-specific win percentages...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating surface-specific win percentages for player A...\n",
            "Calculating surface-specific win percentages for player B...\n",
            "\n",
            "Surface-specific win percentage statistics:\n",
            "Player A surface win pct - mean: 0.492, missing: 4,445\n",
            "Player B surface win pct - mean: 0.492, missing: 6,053\n",
            "Delta surface win pct - mean: 0.001, missing: 8,749\n",
            "Player A no surface history: 4,445 (7.60%)\n",
            "Player B no surface history: 6,053 (10.35%)\n"
          ]
        }
      ],
      "source": [
        "# Calculate surface-specific win percentages for player A and player B\n",
        "print(\"Calculating surface-specific win percentages for player A...\")\n",
        "df['player_A_win_pct_52w_surface'] = df.apply(\n",
        "    lambda row: calculate_surface_win_pct(row, df, row['player_A_id'], 'match_date', 'surface')[0],\n",
        "    axis=1\n",
        ")\n",
        "df['player_A_has_surface_history'] = df.apply(\n",
        "    lambda row: calculate_surface_win_pct(row, df, row['player_A_id'], 'match_date', 'surface')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"Calculating surface-specific win percentages for player B...\")\n",
        "df['player_B_win_pct_52w_surface'] = df.apply(\n",
        "    lambda row: calculate_surface_win_pct(row, df, row['player_B_id'], 'match_date', 'surface')[0],\n",
        "    axis=1\n",
        ")\n",
        "df['player_B_has_surface_history'] = df.apply(\n",
        "    lambda row: calculate_surface_win_pct(row, df, row['player_B_id'], 'match_date', 'surface')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Calculate delta surface win percentage\n",
        "df['delta_win_pct_52w_surface'] = df['player_A_win_pct_52w_surface'] - df['player_B_win_pct_52w_surface']\n",
        "\n",
        "# Create missing-surface-history indicators\n",
        "df['player_A_no_surface_history'] = (~df['player_A_has_surface_history']).astype(int)\n",
        "df['player_B_no_surface_history'] = (~df['player_B_has_surface_history']).astype(int)\n",
        "\n",
        "print(f\"\\nSurface-specific win percentage statistics:\")\n",
        "print(f\"Player A surface win pct - mean: {df['player_A_win_pct_52w_surface'].mean():.3f}, missing: {df['player_A_win_pct_52w_surface'].isna().sum():,}\")\n",
        "print(f\"Player B surface win pct - mean: {df['player_B_win_pct_52w_surface'].mean():.3f}, missing: {df['player_B_win_pct_52w_surface'].isna().sum():,}\")\n",
        "print(f\"Delta surface win pct - mean: {df['delta_win_pct_52w_surface'].mean():.3f}, missing: {df['delta_win_pct_52w_surface'].isna().sum():,}\")\n",
        "print(f\"Player A no surface history: {df['player_A_no_surface_history'].sum():,} ({df['player_A_no_surface_history'].mean():.2%})\")\n",
        "print(f\"Player B no surface history: {df['player_B_no_surface_history'].sum():,} ({df['player_B_no_surface_history'].mean():.2%})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 46,259 rows (2006-2021)\n",
            "Test set:      8,979 rows (2022-2024)\n"
          ]
        }
      ],
      "source": [
        "# Re-split dataset with surface-specific features (same temporal split)\n",
        "df['year'] = pd.to_numeric(\n",
        "    df['tourney_date'].astype(str).str[:4], \n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "train_mask = (df['year'] >= 2006) & (df['year'] <= 2021)\n",
        "test_mask = (df['year'] >= 2022) & (df['year'] <= 2024)\n",
        "\n",
        "df_train = df[train_mask].copy()\n",
        "df_test = df[test_mask].copy()\n",
        "\n",
        "print(f\"Training set: {len(df_train):,} rows (2006-2021)\")\n",
        "print(f\"Test set:      {len(df_test):,} rows (2022-2024)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "  Features shape: (46259, 14)\n",
            "  Target shape: (46259,)\n",
            "\n",
            "Test set:\n",
            "  Features shape: (8979, 14)\n",
            "  Target shape: (8979,)\n",
            "\n",
            "Features (14): ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points_missing', 'delta_rank_missing', 'delta_age_missing', 'delta_ht_missing', 'delta_win_pct_52w', 'player_A_no_history', 'player_B_no_history', 'delta_win_pct_52w_surface', 'player_A_no_surface_history', 'player_B_no_surface_history']\n",
            "\n",
            "Missing values in training set:\n",
            "delta_rank_points              0\n",
            "delta_rank                     0\n",
            "delta_age                      0\n",
            "delta_ht                       0\n",
            "delta_rank_points_missing      0\n",
            "delta_rank_missing             0\n",
            "delta_age_missing              0\n",
            "delta_ht_missing               0\n",
            "delta_win_pct_52w              0\n",
            "player_A_no_history            0\n",
            "player_B_no_history            0\n",
            "delta_win_pct_52w_surface      0\n",
            "player_A_no_surface_history    0\n",
            "player_B_no_surface_history    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Select features including surface-specific win percentage features\n",
        "delta_features = ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht']\n",
        "missing_indicators = [f'{feat}_missing' for feat in delta_features]\n",
        "win_pct_features = ['delta_win_pct_52w']\n",
        "history_indicators = ['player_A_no_history', 'player_B_no_history']\n",
        "surface_win_pct_features = ['delta_win_pct_52w_surface']\n",
        "surface_history_indicators = ['player_A_no_surface_history', 'player_B_no_surface_history']\n",
        "\n",
        "feature_cols = delta_features + missing_indicators + win_pct_features + history_indicators + surface_win_pct_features + surface_history_indicators\n",
        "target_col = 'target'\n",
        "\n",
        "# Create feature matrices and target vectors\n",
        "X_train = df_train[feature_cols].copy()\n",
        "X_test = df_test[feature_cols].copy()\n",
        "y_train = df_train[target_col]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "# Impute missing values in win percentages with 0 (for players with no history)\n",
        "X_train['delta_win_pct_52w'] = X_train['delta_win_pct_52w'].fillna(0)\n",
        "X_test['delta_win_pct_52w'] = X_test['delta_win_pct_52w'].fillna(0)\n",
        "X_train['delta_win_pct_52w_surface'] = X_train['delta_win_pct_52w_surface'].fillna(0)\n",
        "X_test['delta_win_pct_52w_surface'] = X_test['delta_win_pct_52w_surface'].fillna(0)\n",
        "\n",
        "print(f\"Training set:\")\n",
        "print(f\"  Features shape: {X_train.shape}\")\n",
        "print(f\"  Target shape: {y_train.shape}\")\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Features shape: {X_test.shape}\")\n",
        "print(f\"  Target shape: {y_test.shape}\")\n",
        "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
        "print(f\"\\nMissing values in training set:\")\n",
        "print(X_train.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized training features - mean values (should be near zero):\n",
            "delta_rank_points             -0.0\n",
            "delta_rank                     0.0\n",
            "delta_age                     -0.0\n",
            "delta_ht                       0.0\n",
            "delta_rank_points_missing     -0.0\n",
            "delta_rank_missing            -0.0\n",
            "delta_age_missing              0.0\n",
            "delta_ht_missing               0.0\n",
            "delta_win_pct_52w             -0.0\n",
            "player_A_no_history            0.0\n",
            "player_B_no_history            0.0\n",
            "delta_win_pct_52w_surface     -0.0\n",
            "player_A_no_surface_history   -0.0\n",
            "player_B_no_surface_history    0.0\n",
            "dtype: float64\n",
            "\n",
            "Standardized training features - std values (should be ~1.0):\n",
            "delta_rank_points              1.000011\n",
            "delta_rank                     1.000011\n",
            "delta_age                      1.000011\n",
            "delta_ht                       1.000011\n",
            "delta_rank_points_missing      1.000011\n",
            "delta_rank_missing             1.000011\n",
            "delta_age_missing              1.000011\n",
            "delta_ht_missing               1.000011\n",
            "delta_win_pct_52w              1.000011\n",
            "player_A_no_history            1.000011\n",
            "player_B_no_history            1.000011\n",
            "delta_win_pct_52w_surface      1.000011\n",
            "player_A_no_surface_history    1.000011\n",
            "player_B_no_surface_history    1.000011\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Standardize features using StandardScaler (with surface-specific win percentage features)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit scaler on training data only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrames to preserve column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Standardized training features - mean values (should be near zero):\")\n",
        "print(X_train_scaled.mean().round(6))\n",
        "print(f\"\\nStandardized training features - std values (should be ~1.0):\")\n",
        "print(X_train_scaled.std().round(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model Trained (with surface-specific win percentage features)\n",
            "Number of iterations: 11\n",
            "Regularization strength (C): 1.0\n"
          ]
        }
      ],
      "source": [
        "# Retrain logistic regression model with surface-specific win percentage features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Use default regularization (C=1.0)\n",
        "lr_model_surface = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model_surface.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Logistic Regression Model Trained (with surface-specific win percentage features)\")\n",
        "print(f\"Number of iterations: {lr_model_surface.n_iter_[0]}\")\n",
        "print(f\"Regularization strength (C): {lr_model_surface.C}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance on Test Set (with surface-specific win percentage features):\n",
            "======================================================================\n",
            "ROC AUC:  0.7051\n",
            "Log Loss: 0.6280\n",
            "\n",
            "======================================================================\n",
            "Model Coefficients (including surface-specific win percentage and history indicators):\n",
            "======================================================================\n",
            "                    feature  coefficient\n",
            "          delta_rank_points     0.588654\n",
            "                 delta_rank    -0.346537\n",
            "  delta_win_pct_52w_surface     0.262349\n",
            "player_B_no_surface_history     0.142599\n",
            "player_A_no_surface_history    -0.121118\n",
            "          delta_win_pct_52w     0.119240\n",
            "                   delta_ht     0.089405\n",
            "                  delta_age    -0.065514\n",
            "        player_B_no_history     0.046551\n",
            "  delta_rank_points_missing     0.042409\n",
            "         delta_rank_missing     0.042409\n",
            "           delta_ht_missing     0.039033\n",
            "        player_A_no_history    -0.026788\n",
            "          delta_age_missing    -0.024971\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_pred_proba = lr_model_surface.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "log_loss_score = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Model Performance on Test Set (with surface-specific win percentage features):\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"ROC AUC:  {roc_auc:.4f}\")\n",
        "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
        "\n",
        "# Display updated coefficients including all features\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Model Coefficients (including surface-specific win percentage and history indicators):\")\n",
        "print(\"=\" * 70)\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'coefficient': lr_model_surface.coef_[0]\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coefficients['abs_coefficient'] = coefficients['coefficient'].abs()\n",
        "coefficients = coefficients.sort_values('abs_coefficient', ascending=False).drop(columns='abs_coefficient')\n",
        "\n",
        "print(coefficients.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating last-10-weeks (70-day) win percentages...\n"
          ]
        }
      ],
      "source": [
        "# Calculate rolling last-10-weeks (70 days) win percentage for each player\n",
        "# Only use matches played in the 70 days prior to the current match date\n",
        "\n",
        "def calculate_10w_win_pct(row, df_all, player_id, date_col):\n",
        "    \"\"\"Calculate 70-day rolling win percentage for a player, excluding current match\"\"\"\n",
        "    match_date = row[date_col]\n",
        "    \n",
        "    if pd.isna(match_date) or pd.isna(player_id):\n",
        "        return np.nan, False  # (win_pct, has_history)\n",
        "    \n",
        "    # Define 70-day window (70 days before current match)\n",
        "    window_start = match_date - pd.Timedelta(days=70)\n",
        "    \n",
        "    # Get all matches for this player in the 70-day window, excluding current match\n",
        "    # Player can be either player A or player B\n",
        "    player_matches = df_all[\n",
        "        ((df_all['player_A_id'] == player_id) | (df_all['player_B_id'] == player_id)) &\n",
        "        (df_all[date_col] >= window_start) &\n",
        "        (df_all[date_col] < match_date)  # Exclude current match\n",
        "    ].copy()\n",
        "    \n",
        "    if len(player_matches) == 0:\n",
        "        return np.nan, False  # No history in last 10 weeks\n",
        "    \n",
        "    # Calculate wins: player wins if they are player A and target=1, or player B and target=0\n",
        "    wins = (\n",
        "        ((player_matches['player_A_id'] == player_id) & (player_matches['target'] == 1)) |\n",
        "        ((player_matches['player_B_id'] == player_id) & (player_matches['target'] == 0))\n",
        "    ).sum()\n",
        "    \n",
        "    total_matches = len(player_matches)\n",
        "    win_pct = wins / total_matches if total_matches > 0 else np.nan\n",
        "    \n",
        "    return win_pct, True\n",
        "\n",
        "print(\"Calculating last-10-weeks (70-day) win percentages...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating last-10-weeks win percentages for player A...\n",
            "Calculating last-10-weeks win percentages for player B...\n",
            "\n",
            "Last-10-weeks win percentage statistics:\n",
            "Player A 10w win pct - mean: 0.468, missing: 6,785\n",
            "Player B 10w win pct - mean: 0.482, missing: 8,345\n",
            "Delta 10w win pct - mean: -0.013, missing: 12,100\n",
            "Player A no 10w history: 6,785 (11.60%)\n",
            "Player B no 10w history: 8,345 (14.26%)\n"
          ]
        }
      ],
      "source": [
        "# Calculate last-10-weeks win percentages for player A and player B\n",
        "print(\"Calculating last-10-weeks win percentages for player A...\")\n",
        "df['player_A_win_pct_10w'] = df.apply(\n",
        "    lambda row: calculate_10w_win_pct(row, df, row['player_A_id'], 'match_date')[0],\n",
        "    axis=1\n",
        ")\n",
        "df['player_A_has_10w_history'] = df.apply(\n",
        "    lambda row: calculate_10w_win_pct(row, df, row['player_A_id'], 'match_date')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"Calculating last-10-weeks win percentages for player B...\")\n",
        "df['player_B_win_pct_10w'] = df.apply(\n",
        "    lambda row: calculate_10w_win_pct(row, df, row['player_B_id'], 'match_date')[0],\n",
        "    axis=1\n",
        ")\n",
        "df['player_B_has_10w_history'] = df.apply(\n",
        "    lambda row: calculate_10w_win_pct(row, df, row['player_B_id'], 'match_date')[1],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Calculate delta win percentage (Player A - Player B)\n",
        "df['delta_win_pct_10w'] = df['player_A_win_pct_10w'] - df['player_B_win_pct_10w']\n",
        "\n",
        "# Create binary indicators for players with no matches in the last 10 weeks\n",
        "df['player_A_no_10w_history'] = (~df['player_A_has_10w_history']).astype(int)\n",
        "df['player_B_no_10w_history'] = (~df['player_B_has_10w_history']).astype(int)\n",
        "\n",
        "print(f\"\\nLast-10-weeks win percentage statistics:\")\n",
        "print(f\"Player A 10w win pct - mean: {df['player_A_win_pct_10w'].mean():.3f}, missing: {df['player_A_win_pct_10w'].isna().sum():,}\")\n",
        "print(f\"Player B 10w win pct - mean: {df['player_B_win_pct_10w'].mean():.3f}, missing: {df['player_B_win_pct_10w'].isna().sum():,}\")\n",
        "print(f\"Delta 10w win pct - mean: {df['delta_win_pct_10w'].mean():.3f}, missing: {df['delta_win_pct_10w'].isna().sum():,}\")\n",
        "print(f\"Player A no 10w history: {df['player_A_no_10w_history'].sum():,} ({df['player_A_no_10w_history'].mean():.2%})\")\n",
        "print(f\"Player B no 10w history: {df['player_B_no_10w_history'].sum():,} ({df['player_B_no_10w_history'].mean():.2%})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 46,259 rows (2006-2021)\n",
            "Test set:      8,979 rows (2022-2024)\n"
          ]
        }
      ],
      "source": [
        "# Re-split dataset with last-10-weeks features (same temporal split)\n",
        "df['year'] = pd.to_numeric(\n",
        "    df['tourney_date'].astype(str).str[:4], \n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "train_mask = (df['year'] >= 2006) & (df['year'] <= 2021)\n",
        "test_mask = (df['year'] >= 2022) & (df['year'] <= 2024)\n",
        "\n",
        "df_train = df[train_mask].copy()\n",
        "df_test = df[test_mask].copy()\n",
        "\n",
        "print(f\"Training set: {len(df_train):,} rows (2006-2021)\")\n",
        "print(f\"Test set:      {len(df_test):,} rows (2022-2024)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "  Features shape: (46259, 17)\n",
            "  Target shape: (46259,)\n",
            "\n",
            "Test set:\n",
            "  Features shape: (8979, 17)\n",
            "  Target shape: (8979,)\n",
            "\n",
            "Features (17): ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht', 'delta_rank_points_missing', 'delta_rank_missing', 'delta_age_missing', 'delta_ht_missing', 'delta_win_pct_52w', 'player_A_no_history', 'player_B_no_history', 'delta_win_pct_52w_surface', 'player_A_no_surface_history', 'player_B_no_surface_history', 'delta_win_pct_10w', 'player_A_no_10w_history', 'player_B_no_10w_history']\n",
            "\n",
            "Missing values in training set:\n",
            "delta_rank_points              0\n",
            "delta_rank                     0\n",
            "delta_age                      0\n",
            "delta_ht                       0\n",
            "delta_rank_points_missing      0\n",
            "delta_rank_missing             0\n",
            "delta_age_missing              0\n",
            "delta_ht_missing               0\n",
            "delta_win_pct_52w              0\n",
            "player_A_no_history            0\n",
            "player_B_no_history            0\n",
            "delta_win_pct_52w_surface      0\n",
            "player_A_no_surface_history    0\n",
            "player_B_no_surface_history    0\n",
            "delta_win_pct_10w              0\n",
            "player_A_no_10w_history        0\n",
            "player_B_no_10w_history        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Select features including last-10-weeks win percentage features\n",
        "delta_features = ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht']\n",
        "missing_indicators = [f'{feat}_missing' for feat in delta_features]\n",
        "win_pct_features = ['delta_win_pct_52w']\n",
        "history_indicators = ['player_A_no_history', 'player_B_no_history']\n",
        "surface_win_pct_features = ['delta_win_pct_52w_surface']\n",
        "surface_history_indicators = ['player_A_no_surface_history', 'player_B_no_surface_history']\n",
        "win_pct_10w_features = ['delta_win_pct_10w']\n",
        "history_10w_indicators = ['player_A_no_10w_history', 'player_B_no_10w_history']\n",
        "\n",
        "feature_cols = (delta_features + missing_indicators + win_pct_features + history_indicators + \n",
        "                surface_win_pct_features + surface_history_indicators + \n",
        "                win_pct_10w_features + history_10w_indicators)\n",
        "target_col = 'target'\n",
        "\n",
        "# Create feature matrices and target vectors\n",
        "X_train = df_train[feature_cols].copy()\n",
        "X_test = df_test[feature_cols].copy()\n",
        "y_train = df_train[target_col]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "# Impute missing values in win percentages with 0 (for players with no history)\n",
        "X_train['delta_win_pct_52w'] = X_train['delta_win_pct_52w'].fillna(0)\n",
        "X_test['delta_win_pct_52w'] = X_test['delta_win_pct_52w'].fillna(0)\n",
        "X_train['delta_win_pct_52w_surface'] = X_train['delta_win_pct_52w_surface'].fillna(0)\n",
        "X_test['delta_win_pct_52w_surface'] = X_test['delta_win_pct_52w_surface'].fillna(0)\n",
        "X_train['delta_win_pct_10w'] = X_train['delta_win_pct_10w'].fillna(0)\n",
        "X_test['delta_win_pct_10w'] = X_test['delta_win_pct_10w'].fillna(0)\n",
        "\n",
        "print(f\"Training set:\")\n",
        "print(f\"  Features shape: {X_train.shape}\")\n",
        "print(f\"  Target shape: {y_train.shape}\")\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Features shape: {X_test.shape}\")\n",
        "print(f\"  Target shape: {y_test.shape}\")\n",
        "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
        "print(f\"\\nMissing values in training set:\")\n",
        "print(X_train.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized training features - mean values (should be near zero):\n",
            "delta_rank_points             -0.0\n",
            "delta_rank                     0.0\n",
            "delta_age                     -0.0\n",
            "delta_ht                       0.0\n",
            "delta_rank_points_missing     -0.0\n",
            "delta_rank_missing            -0.0\n",
            "delta_age_missing              0.0\n",
            "delta_ht_missing               0.0\n",
            "delta_win_pct_52w             -0.0\n",
            "player_A_no_history            0.0\n",
            "player_B_no_history            0.0\n",
            "delta_win_pct_52w_surface     -0.0\n",
            "player_A_no_surface_history   -0.0\n",
            "player_B_no_surface_history    0.0\n",
            "delta_win_pct_10w             -0.0\n",
            "player_A_no_10w_history       -0.0\n",
            "player_B_no_10w_history       -0.0\n",
            "dtype: float64\n",
            "\n",
            "Standardized training features - std values (should be ~1.0):\n",
            "delta_rank_points              1.000011\n",
            "delta_rank                     1.000011\n",
            "delta_age                      1.000011\n",
            "delta_ht                       1.000011\n",
            "delta_rank_points_missing      1.000011\n",
            "delta_rank_missing             1.000011\n",
            "delta_age_missing              1.000011\n",
            "delta_ht_missing               1.000011\n",
            "delta_win_pct_52w              1.000011\n",
            "player_A_no_history            1.000011\n",
            "player_B_no_history            1.000011\n",
            "delta_win_pct_52w_surface      1.000011\n",
            "player_A_no_surface_history    1.000011\n",
            "player_B_no_surface_history    1.000011\n",
            "delta_win_pct_10w              1.000011\n",
            "player_A_no_10w_history        1.000011\n",
            "player_B_no_10w_history        1.000011\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Standardize features using StandardScaler (with last-10-weeks win percentage features)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit scaler on training data only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrames to preserve column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Standardized training features - mean values (should be near zero):\")\n",
        "print(X_train_scaled.mean().round(6))\n",
        "print(f\"\\nStandardized training features - std values (should be ~1.0):\")\n",
        "print(X_train_scaled.std().round(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model Trained (with last-10-weeks win percentage features)\n",
            "Number of iterations: 11\n",
            "Regularization strength (C): 1.0\n"
          ]
        }
      ],
      "source": [
        "# Retrain logistic regression model with last-10-weeks win percentage features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Use default regularization (C=1.0)\n",
        "lr_model_10w = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model_10w.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Logistic Regression Model Trained (with last-10-weeks win percentage features)\")\n",
        "print(f\"Number of iterations: {lr_model_10w.n_iter_[0]}\")\n",
        "print(f\"Regularization strength (C): {lr_model_10w.C}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance on Test Set (with last-10-weeks win percentage features):\n",
            "======================================================================\n",
            "ROC AUC:  0.7086\n",
            "Log Loss: 0.6253\n",
            "\n",
            "======================================================================\n",
            "Model Coefficients (including last-10-weeks win percentage and history indicators):\n",
            "======================================================================\n",
            "                    feature  coefficient\n",
            "          delta_rank_points     0.565192\n",
            "                 delta_rank    -0.307678\n",
            "  delta_win_pct_52w_surface     0.236121\n",
            "          delta_win_pct_10w     0.159672\n",
            "player_B_no_surface_history     0.124845\n",
            "player_A_no_surface_history    -0.109921\n",
            "    player_B_no_10w_history     0.103795\n",
            "                   delta_ht     0.086545\n",
            "    player_A_no_10w_history    -0.082406\n",
            "                  delta_age    -0.061415\n",
            "          delta_win_pct_52w     0.055460\n",
            "         delta_rank_missing     0.042720\n",
            "  delta_rank_points_missing     0.042720\n",
            "           delta_ht_missing     0.038614\n",
            "          delta_age_missing    -0.024972\n",
            "        player_B_no_history     0.024965\n",
            "        player_A_no_history    -0.014227\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_pred_proba = lr_model_10w.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "log_loss_score = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Model Performance on Test Set (with last-10-weeks win percentage features):\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"ROC AUC:  {roc_auc:.4f}\")\n",
        "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
        "\n",
        "# Display updated coefficients including all features\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Model Coefficients (including last-10-weeks win percentage and history indicators):\")\n",
        "print(\"=\" * 70)\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'coefficient': lr_model_10w.coef_[0]\n",
        "})\n",
        "\n",
        "# Sort by absolute value of coefficient\n",
        "coefficients['abs_coefficient'] = coefficients['coefficient'].abs()\n",
        "coefficients = coefficients.sort_values('abs_coefficient', ascending=False).drop(columns='abs_coefficient')\n",
        "\n",
        "print(coefficients.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance Comparison:\n",
            "================================================================================\n",
            "Metric               Before (Surface)     After (+10-week)     Change              \n",
            "--------------------------------------------------------------------------------\n",
            "ROC AUC              0.7051               0.7086               +0.0035\n",
            "Log Loss             0.6280               0.6253               -0.0027\n",
            "================================================================================\n",
            "\n",
            "Percentage Improvements:\n",
            "  ROC AUC: +0.49%\n",
            "  Log Loss: -0.44% (lower is better)\n",
            "\n",
            "================================================================================\n",
            "Summary Assessment:\n",
            "================================================================================\n",
            "~ Small improvement in ROC AUC (<0.005 increase)\n",
            "~ Small improvement in Log Loss (<0.005 decrease)\n",
            "\n",
            "Overall: The addition of last-10-weeks features provides modest improvement.\n"
          ]
        }
      ],
      "source": [
        "# Compare model performance before and after adding last-10-weeks features\n",
        "# Note: We need to evaluate both models on their respective feature sets\n",
        "\n",
        "# Re-create feature sets for comparison\n",
        "# Surface model features (before 10-week)\n",
        "delta_features = ['delta_rank_points', 'delta_rank', 'delta_age', 'delta_ht']\n",
        "missing_indicators = [f'{feat}_missing' for feat in delta_features]\n",
        "win_pct_features = ['delta_win_pct_52w']\n",
        "history_indicators = ['player_A_no_history', 'player_B_no_history']\n",
        "surface_win_pct_features = ['delta_win_pct_52w_surface']\n",
        "surface_history_indicators = ['player_A_no_surface_history', 'player_B_no_surface_history']\n",
        "feature_cols_surface = (delta_features + missing_indicators + win_pct_features + history_indicators + \n",
        "                        surface_win_pct_features + surface_history_indicators)\n",
        "\n",
        "# 10-week model features (after 10-week)\n",
        "win_pct_10w_features = ['delta_win_pct_10w']\n",
        "history_10w_indicators = ['player_A_no_10w_history', 'player_B_no_10w_history']\n",
        "feature_cols_10w = feature_cols_surface + win_pct_10w_features + history_10w_indicators\n",
        "\n",
        "# Prepare test sets for each model\n",
        "X_test_surface = df_test[feature_cols_surface].copy()\n",
        "X_test_10w = df_test[feature_cols_10w].copy()\n",
        "\n",
        "# Impute missing values\n",
        "for col in ['delta_win_pct_52w', 'delta_win_pct_52w_surface']:\n",
        "    if col in X_test_surface.columns:\n",
        "        X_test_surface[col] = X_test_surface[col].fillna(0)\n",
        "        X_test_10w[col] = X_test_10w[col].fillna(0)\n",
        "for col in ['delta_win_pct_10w']:\n",
        "    if col in X_test_10w.columns:\n",
        "        X_test_10w[col] = X_test_10w[col].fillna(0)\n",
        "\n",
        "# Standardize test sets using scalers fitted on training data\n",
        "# For surface model - need to recreate scaler\n",
        "X_train_surface = df_train[feature_cols_surface].copy()\n",
        "for col in ['delta_win_pct_52w', 'delta_win_pct_52w_surface']:\n",
        "    if col in X_train_surface.columns:\n",
        "        X_train_surface[col] = X_train_surface[col].fillna(0)\n",
        "scaler_surface = StandardScaler()\n",
        "scaler_surface.fit(X_train_surface)\n",
        "X_test_surface_scaled = pd.DataFrame(\n",
        "    scaler_surface.transform(X_test_surface),\n",
        "    columns=X_test_surface.columns,\n",
        "    index=X_test_surface.index\n",
        ")\n",
        "\n",
        "# For 10-week model - use existing scaler\n",
        "X_test_10w_scaled = X_test_scaled[feature_cols_10w]\n",
        "\n",
        "# Get predictions\n",
        "y_pred_proba_surface = lr_model_surface.predict_proba(X_test_surface_scaled)[:, 1]\n",
        "roc_auc_surface = roc_auc_score(y_test, y_pred_proba_surface)\n",
        "log_loss_surface = log_loss(y_test, y_pred_proba_surface)\n",
        "\n",
        "y_pred_proba_10w = lr_model_10w.predict_proba(X_test_10w_scaled)[:, 1]\n",
        "roc_auc_10w = roc_auc_score(y_test, y_pred_proba_10w)\n",
        "log_loss_10w = log_loss(y_test, y_pred_proba_10w)\n",
        "\n",
        "# Calculate improvements\n",
        "roc_auc_improvement = roc_auc_10w - roc_auc_surface\n",
        "log_loss_improvement = log_loss_10w - log_loss_surface # Lower is better, so improvement is positive\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Metric':<20} {'Before (Surface)':<20} {'After (+10-week)':<20} {'Change':<20}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'ROC AUC':<20} {roc_auc_surface:<20.4f} {roc_auc_10w:<20.4f} {roc_auc_improvement:+.4f}\")\n",
        "print(f\"{'Log Loss':<20} {log_loss_surface:<20.4f} {log_loss_10w:<20.4f} {log_loss_improvement:+.4f}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate percentage improvements\n",
        "roc_auc_pct_improvement = (roc_auc_improvement / roc_auc_surface) * 100\n",
        "log_loss_pct_improvement = (log_loss_improvement / log_loss_surface) * 100\n",
        "\n",
        "print(f\"\\nPercentage Improvements:\")\n",
        "print(f\"  ROC AUC: {roc_auc_pct_improvement:+.2f}%\")\n",
        "print(f\"  Log Loss: {log_loss_pct_improvement:+.2f}% (lower is better)\")\n",
        "\n",
        "# Summary assessment\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Summary Assessment:\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if roc_auc_improvement > 0.01:\n",
        "    print(\"âœ“ Meaningful improvement in ROC AUC (>0.01 increase)\")\n",
        "elif roc_auc_improvement > 0.005:\n",
        "    print(\"~ Modest improvement in ROC AUC (0.005-0.01 increase)\")\n",
        "elif roc_auc_improvement > 0:\n",
        "    print(\"~ Small improvement in ROC AUC (<0.005 increase)\")\n",
        "else:\n",
        "    print(\"âœ— No improvement or slight decrease in ROC AUC\")\n",
        "\n",
        "if abs(log_loss_improvement) > 0.01:\n",
        "    print(\"âœ“ Meaningful improvement in Log Loss (>0.01 decrease)\")\n",
        "elif abs(log_loss_improvement) > 0.005:\n",
        "    print(\"~ Modest improvement in Log Loss (0.005-0.01 decrease)\")\n",
        "elif abs(log_loss_improvement) > 0:\n",
        "    print(\"~ Small improvement in Log Loss (<0.005 decrease)\")\n",
        "else:\n",
        "    print(\"âœ— No improvement or slight increase in Log Loss\")\n",
        "\n",
        "# Overall assessment\n",
        "if roc_auc_improvement > 0.005 and abs(log_loss_improvement) > 0.005:\n",
        "    print(f\"\\nOverall: The addition of last-10-weeks features provides a meaningful improvement.\")\n",
        "elif roc_auc_improvement > 0 or abs(log_loss_improvement) > 0:\n",
        "    print(f\"\\nOverall: The addition of last-10-weeks features provides modest improvement.\")\n",
        "else:\n",
        "    print(f\"\\nOverall: The addition of last-10-weeks features does not meaningfully improve performance.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
